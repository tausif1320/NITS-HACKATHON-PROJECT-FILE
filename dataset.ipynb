{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "geM79RsaO-k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Step 1: Set Kaggle API credentials\n",
        "os.environ['KAGGLE_USERNAME'] = 'bhargavsaisanapala'\n",
        "os.environ['KAGGLE_KEY'] = 'a6cbb0f1353e12f36a5b936c5c1219d3'\n",
        "\n",
        "# Step 2: Initialize Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Step 3: Download the dataset using the Kaggle API\n",
        "dataset = 'tushar5harma/plant-village-dataset-updated'  # Specify the dataset path\n",
        "output_dir = './'  # Specify the output directory where you want to save the dataset\n",
        "\n",
        "# Download the dataset and save as a zip file\n",
        "api.dataset_download_files(dataset, path=output_dir, unzip=False)\n",
        "\n",
        "# Step 4: Unzip the downloaded dataset\n",
        "zip_file_path = os.path.join(output_dir, 'plant-village-dataset-updated.zip')\n",
        "\n",
        "# Unzipping the dataset\n",
        "print(\"Zip file found, extracting...\")\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "print(\"Extraction completed.\")\n",
        "\n",
        "# Step 5: Check the current directory for the extracted folder\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"Files and directories in the current directory:\", os.listdir(output_dir))\n",
        "\n",
        "# Step 6: Identify the correct extracted folder\n",
        "data_dir = None\n",
        "\n",
        "# Check for directories that could contain the images\n",
        "for item in os.listdir(output_dir):\n",
        "    item_path = os.path.join(output_dir, item)\n",
        "    if os.path.isdir(item_path) and item not in ['.config', 'sample_data']:\n",
        "        data_dir = item_path\n",
        "        break\n",
        "\n",
        "if not data_dir:\n",
        "    raise FileNotFoundError(\"No valid dataset directory found.\")\n",
        "\n",
        "print(\"Using dataset directory:\", data_dir)\n",
        "\n",
        "# Step 7: Load images and labels\n",
        "train_dir = os.path.join(data_dir, 'Train')  # Path for training images\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "valid_extensions = ['.jpg', '.jpeg', '.png']  # Valid image formats\n",
        "\n",
        "# Initialize categories list\n",
        "categories = []\n",
        "\n",
        "# Load images from the 'Train' directory\n",
        "if os.path.exists(train_dir):\n",
        "    # Populate the categories list\n",
        "    categories = os.listdir(train_dir)\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(train_dir, category)\n",
        "\n",
        "        # Check if the path is indeed a directory\n",
        "        if not os.path.isdir(category_path):\n",
        "            print(f\"Skipping non-directory: {category_path}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Loading images from category: {category}\")  # Debug info\n",
        "\n",
        "        for img_name in os.listdir(category_path):\n",
        "            if not any(img_name.lower().endswith(ext) for ext in valid_extensions):\n",
        "                continue\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Warning: {img_path} could not be read.\")\n",
        "                continue\n",
        "            img = cv2.resize(img, (128, 128))  # Resize images for uniformity\n",
        "            images.append(img)\n",
        "            labels.append(categories.index(category))  # Use index of category in the list\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Training directory '{train_dir}' not found.\")\n",
        "\n",
        "# Check if images were loaded\n",
        "if not images:\n",
        "    raise ValueError(\"No images were loaded. Please check the image paths and formats.\")\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Step 9: Normalize the image data\n",
        "X = X.astype('float32') / 255.0  # Scale pixel values to [0, 1]\n",
        "\n",
        "# Step 10: Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 11: Build a simple CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(categories), activation='softmax')  # Output layer for number of categories\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 12: Train the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKC1xDlwcLe4",
        "outputId": "d7b042d7-e4cb-478e-a223-ed40aa2210d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/tushar5harma/plant-village-dataset-updated\n",
            "Zip file found, extracting...\n",
            "Extraction completed.\n",
            "Current working directory: /content\n",
            "Files and directories in the current directory: ['.config', 'Tomato', 'Strawberry', 'plant-village-dataset-updated.zip', 'content', 'Potato', 'Corn (Maize)', 'Bell Pepper', 'Grape', 'Peach', 'Apple', 'Cherry', 'sample_data']\n",
            "Using dataset directory: ./Tomato\n",
            "Loading images from category: Healthy\n",
            "Loading images from category: Early Blight\n",
            "Loading images from category: Bacterial Spot\n",
            "Loading images from category: Yellow Leaf Curl Virus\n",
            "Loading images from category: Septoria Leaf Spot\n",
            "Loading images from category: Late Blight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.5194 - loss: 1.1882 - val_accuracy: 0.8213 - val_loss: 0.4896\n",
            "Epoch 2/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.8483 - loss: 0.4181 - val_accuracy: 0.7821 - val_loss: 0.5518\n",
            "Epoch 3/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.8922 - loss: 0.2990 - val_accuracy: 0.8379 - val_loss: 0.4649\n",
            "Epoch 4/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.9238 - loss: 0.2086 - val_accuracy: 0.9199 - val_loss: 0.2331\n",
            "Epoch 5/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.9589 - loss: 0.1210 - val_accuracy: 0.9230 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.9683 - loss: 0.0936 - val_accuracy: 0.8915 - val_loss: 0.3128\n",
            "Epoch 7/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.9745 - loss: 0.0762 - val_accuracy: 0.8676 - val_loss: 0.4679\n",
            "Epoch 8/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.9764 - loss: 0.0669 - val_accuracy: 0.8879 - val_loss: 0.4054\n",
            "Epoch 9/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.9722 - loss: 0.0725 - val_accuracy: 0.9325 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.9951 - loss: 0.0165 - val_accuracy: 0.8393 - val_loss: 0.7155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784cd6f0d420>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lt6456tkcqRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}